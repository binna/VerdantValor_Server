# Verdant Valor Server Project (2025.10.18 ~ 진행 중)

서버 프로젝트입니다.   
웹 서버, 게임 서버, 채팅 서버를 구축하는 것을 목표로 만들고 있습니다.   

▼ 이 프로젝트와 관련된 레파지토리   
- [클라이언트](https://github.com/binna/VerdantValor_Client)    
  Unity 기반 게임 클라이언트입니다.  
- [서버-클라이언트 공통 모듈](https://github.com/binna/VerdantValor_Shared)    
  서버와 클라이언트가 공유하는 파일을 관리합니다.    
- [개발 스케줄 보드](https://github.com/users/binna/projects/1)    
  프로젝트 일정과 작업 계획을 정리한 보드입니다.    

<br><br>

## 기술스택

1. 웹 서버
 
    | 구분 | 기술 |
    |------|------|
    | **Framework** | ASP.NET Core(.NET 9.0), EF Core |
    | **DB** | MySQL, Redis |    

2. 채팅 서버
    | 구분 | 기술 |
    |------|------|
    | **Network** | TCP Socket(TcpClient/TcpListener 기반 예정) |    

<br><br>

## 부록
### A. 에코 TCP 브로드캐스트 서버 테스트
1. 클라이언트 10개를 동시에 서버에 연결한 뒤,  
   서버가 수신한 메시지를 모든 클라이언트에게 브로드캐스트하여    
   정상적으로 전달되는지 확인하는 테스트입니다.
       
   [동영상보기](https://youtu.be/xZfiTMKN-EU)
       
   <details>
     <summary>이미지보기</summary>
     <img width="800" height="1400" alt="image" src="https://github.com/user-attachments/assets/46423cc8-b74b-4971-b620-87aac8450785" />
   </details>

2. 클라이언트 100개를 동시에 서버에 연결한 뒤,  
   서버가 수신한 메시지를 모든 클라이언트에게 브로드캐스트하여    
   정상적으로 전달되는지 확인하는 테스트입니다.
       
   [동영상보기](https://youtu.be/KhASnoavt8o)     

<br>

### B. 에코 TCP 브로드캐스트 서버 구조 분석 및 개선 방향
현재 구현한 에코 TCP 브로드캐스트 서버는    
각 클라이언트 세션마다 전용 `Receive` 스레드를 두는 구조입니다.    
(1 세션 = 1 스레드 = `while(true)` + `Receive`)

#### 장점
- 구현이 단순하고 직관적입니다.   
  따라서 코드 흐름이 명확하여 디버깅이나 테스트가 쉽습니다.   
- 소규모 동접(수십 ~ 많으면 수백)에서는 안정적으로 동작합니다.   

#### 단점
- 세션 수만큼 스레드가 필요합니다.    
  따라서 클라이언트가 증가할수록 스레드 수가 함께 늘어나며
  스레드 풀 고갈, 컨텍스트 스위칭 비용 증가 등의 리소스 낭비가 발생할 수 있습니다.
- 대부분의 스레드가 `Receive`에서 블로킹 대기하여   
  소켓 수가 곧 잠자는 스레드 수가 되는 구조적 문제가 발생할 수 있습니다.   

#### 고려했던 대응 방안
- 클라이언트 연결 수 제한을 고려했습니다.
  지정한 수 이상 연결 요청은 거절하여 리소스를 보호합니다.   
  안정성은 향상되지만, **근본적인 해결책은 아닙니다.**

#### 개선 방향 (채팅 서버에서 반영 예정)
채팅 서버는 이러한 한계를 해결하기 위해    
세션마다 스레드를 쓰는 구조 대신
**OS에서 전달하는 이벤트를 받아 소수의 스레드로 여러 소켓을 처리하는 방식**으로 전환할 예정입니다.   

OS는 소켓의 읽기/쓰기 가능 상태를 이벤트로 알려주고  
소수의 워커 스레드는 이 이벤트를 받아 여러 소켓을 처리합니다   
 > Windows 환경에서는 IOCP로 구현됩니다.

이 방식은 대규모 동접 환경에서도 안정적으로 확장됩니다.
